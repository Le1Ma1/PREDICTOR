{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d93e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 目的：以 LightGBM 預測 y_dir_6h，WF 調參，校準機率，記錄 MLflow\n",
    "# 並加入 Logistic Regression baseline 檢查資料信號\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss, precision_recall_fscore_support\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ========== 0) 參數 ==========\n",
    "FEAT_PATH = Path(\"./data/feat_6h.parquet\")\n",
    "LABEL_PATH = Path(\"./data/label_6h.parquet\")\n",
    "ART_DIR = Path(\"./artifacts_lgbm\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_DAYS = 90\n",
    "TRACKING_URI = \"mlruns\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(\"lgbm_6h\")\n",
    "\n",
    "# ========== 1) 資料 ==========\n",
    "feat = pd.read_parquet(FEAT_PATH)\n",
    "label = pd.read_parquet(LABEL_PATH)\n",
    "\n",
    "df = feat.merge(label, on=\"ts_utc\", how=\"inner\").sort_values(\"ts_utc\").reset_index(drop=True)\n",
    "times = pd.to_datetime(df[\"ts_utc\"], utc=True)\n",
    "\n",
    "y = df[\"y_dir_6h\"].astype(int).values\n",
    "feature_cols = df.drop(columns=[\"ts_utc\", \"y_dir_6h\", \"y_tail_6h\"]).select_dtypes(include=[np.number]).columns\n",
    "X = df[feature_cols].values\n",
    "\n",
    "# 切分\n",
    "test_start_ts = times.max() - pd.Timedelta(days=TEST_DAYS)\n",
    "train_mask = times < test_start_ts\n",
    "test_mask = times >= test_start_ts\n",
    "\n",
    "X_train_raw, y_train_raw, t_train = X[train_mask], y[train_mask], times[train_mask]\n",
    "X_test_raw, y_test_raw, t_test = X[test_mask], y[test_mask], times[test_mask]\n",
    "\n",
    "# 縮放\n",
    "scaler_path = Path(\"./artifacts_tcn/scaler.pkl\")\n",
    "if scaler_path.exists():\n",
    "    scaler = joblib.load(scaler_path)\n",
    "else:\n",
    "    scaler = StandardScaler().fit(X_train_raw)\n",
    "\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# ========== 2) Walk-Forward 切分 ==========\n",
    "def gen_walk_forward_splits(times_arr: pd.Series, train_days=270, val_days=90):\n",
    "    splits = []\n",
    "    start_date = times_arr.min()\n",
    "    end_date = times_arr.max()\n",
    "    cursor = start_date\n",
    "    while True:\n",
    "        train_end = cursor + pd.Timedelta(days=train_days)\n",
    "        val_end = train_end + pd.Timedelta(days=val_days)\n",
    "        if val_end > end_date:\n",
    "            break\n",
    "        tr_idx = (times_arr >= cursor) & (times_arr < train_end)\n",
    "        va_idx = (times_arr >= train_end) & (times_arr < val_end)\n",
    "        if tr_idx.sum() > 200 and va_idx.sum() > 50:\n",
    "            splits.append((np.where(tr_idx)[0], np.where(va_idx)[0]))\n",
    "        cursor = cursor + pd.Timedelta(days=val_days)\n",
    "    if not splits:\n",
    "        n = len(times_arr)\n",
    "        cut = int(n * 0.7)\n",
    "        splits = [(np.arange(0, cut), np.arange(cut, n))]\n",
    "    return splits\n",
    "\n",
    "cv_splits = gen_walk_forward_splits(pd.Series(t_train))\n",
    "\n",
    "# ========== 3) 調參 ==========\n",
    "# Baseline 參數（放寬限制，避免 constant 預測）\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 63, 127],\n",
    "    \"max_depth\": [-1, 7, 15],\n",
    "    \"learning_rate\": [0.05, 0.1],\n",
    "    \"colsample_bytree\": [0.7, 1.0],\n",
    "    \"min_child_samples\": [5, 10, 20],\n",
    "    \"min_data_in_leaf\": [5, 10],\n",
    "    \"reg_lambda\": [0, 1],\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_params = None\n",
    "best_cv_auc = -np.inf\n",
    "oof_preds, oof_labels = [], []\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_cv\") as parent_run:\n",
    "    for i, params in enumerate(grid):\n",
    "        fold_aucs = []\n",
    "        with mlflow.start_run(run_name=f\"param_set_{i}\", nested=True):\n",
    "            for tr_idx, va_idx in cv_splits:\n",
    "                clf = lgb.LGBMClassifier(\n",
    "                    objective=\"binary\",\n",
    "                    metric=\"auc\",\n",
    "                    n_estimators=2000,\n",
    "                    **params\n",
    "                )\n",
    "                clf.fit(\n",
    "                    X_train[tr_idx], y_train_raw[tr_idx],\n",
    "                    eval_set=[(X_train[va_idx], y_train_raw[va_idx])],\n",
    "                    eval_metric=\"auc\",\n",
    "                    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "                )\n",
    "                va_pred = clf.predict_proba(X_train[va_idx])[:, 1]\n",
    "                fold_aucs.append(roc_auc_score(y_train_raw[va_idx], va_pred))\n",
    "\n",
    "            mean_auc = float(np.mean(fold_aucs))\n",
    "            for k, v in params.items():\n",
    "                mlflow.log_param(k, v)\n",
    "            mlflow.log_metric(\"cv_auc\", mean_auc)\n",
    "\n",
    "            if mean_auc > best_cv_auc:\n",
    "                best_cv_auc = mean_auc\n",
    "                best_params = params\n",
    "\n",
    "    # 收集 OOF 預測\n",
    "    for tr_idx, va_idx in cv_splits:\n",
    "        clf = lgb.LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            metric=\"auc\",\n",
    "            n_estimators=2000,\n",
    "            **best_params\n",
    "        )\n",
    "        clf.fit(\n",
    "            X_train[tr_idx], y_train_raw[tr_idx],\n",
    "            eval_set=[(X_train[va_idx], y_train_raw[va_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    "        )\n",
    "        va_pred = clf.predict_proba(X_train[va_idx])[:, 1]\n",
    "        oof_preds.append(va_pred)\n",
    "        oof_labels.append(y_train_raw[va_idx])\n",
    "\n",
    "    oof_preds = np.concatenate(oof_preds)\n",
    "    oof_labels = np.concatenate(oof_labels)\n",
    "    mlflow.log_metric(\"best_cv_auc\", float(best_cv_auc))\n",
    "\n",
    "# ========== 4) 最終模型 ==========\n",
    "final_clf = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    n_estimators=3000,\n",
    "    **best_params\n",
    ")\n",
    "cut = int(len(X_train) * 0.9)\n",
    "final_clf.fit(\n",
    "    X_train[:cut], y_train_raw[:cut],\n",
    "    eval_set=[(X_train[cut:], y_train_raw[cut:])],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    ")\n",
    "\n",
    "proba_test = final_clf.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test_raw, proba_test)\n",
    "brier_test = brier_score_loss(y_test_raw, proba_test)\n",
    "prec, rec, f1, _ = precision_recall_fscore_support((proba_test >= 0.5).astype(int), y_test_raw, average=\"binary\", zero_division=0)\n",
    "\n",
    "# 校準\n",
    "calibrator = IsotonicRegression(out_of_bounds=\"clip\").fit(oof_preds, oof_labels)\n",
    "proba_test_cal = calibrator.transform(proba_test)\n",
    "brier_test_cal = brier_score_loss(y_test_raw, proba_test_cal)\n",
    "\n",
    "# 保存\n",
    "joblib.dump(final_clf, ART_DIR / \"lgbm_model.pkl\")\n",
    "final_clf.booster_.save_model(str(ART_DIR / \"lgbm_model.txt\"))\n",
    "joblib.dump(calibrator, ART_DIR / \"lgbm_calibrator.pkl\")\n",
    "joblib.dump(scaler, ART_DIR / \"scaler.pkl\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_final\"):\n",
    "    for k, v in best_params.items():\n",
    "        mlflow.log_param(k, v)\n",
    "    mlflow.log_metric(\"test_auc_raw\", float(auc_test))\n",
    "    mlflow.log_metric(\"test_brier_raw\", float(brier_test))\n",
    "    mlflow.log_metric(\"test_brier_cal\", float(brier_test_cal))\n",
    "    mlflow.log_metric(\"precision_thr_0_5\", float(prec))\n",
    "    mlflow.log_metric(\"recall_thr_0_5\", float(rec))\n",
    "    mlflow.log_metric(\"f1_thr_0_5\", float(f1))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_model.pkl\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_model.txt\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_calibrator.pkl\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"scaler.pkl\"))\n",
    "\n",
    "print({\n",
    "    \"best_cv_auc\": float(best_cv_auc),\n",
    "    \"test_auc_raw\": float(auc_test),\n",
    "    \"test_brier_raw\": float(brier_test),\n",
    "    \"test_brier_cal\": float(brier_test_cal),\n",
    "})\n",
    "\n",
    "# ========== 5) Logistic Regression baseline ==========\n",
    "print(\"\\n===== Logistic Regression baseline =====\")\n",
    "log_clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "log_clf.fit(X_train, y_train_raw)\n",
    "log_proba = log_clf.predict_proba(X_test)[:, 1]\n",
    "\n",
    "auc_log = roc_auc_score(y_test_raw, log_proba)\n",
    "brier_log = brier_score_loss(y_test_raw, log_proba)\n",
    "\n",
    "print({\n",
    "    \"logreg_auc\": float(auc_log),\n",
    "    \"logreg_brier\": float(brier_log)\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
