{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3d93e3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 目的：以 LightGBM 預測 y_dir_6h，WF 調參，校準機率，記錄 MLflow\n",
    "\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import mlflow\n",
    "from sklearn.metrics import roc_auc_score, brier_score_loss\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# ========== 0) 參數 ==========\n",
    "FEAT_PATH = Path(\"./data/feat_6h.parquet\")\n",
    "LABEL_PATH = Path(\"./data/label_6h.parquet\")\n",
    "ART_DIR = Path(\"./artifacts_lgbm\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TEST_DAYS = 90\n",
    "FREQ_PER_DAY = 4\n",
    "TRACKING_URI = \"mlruns\"\n",
    "\n",
    "mlflow.set_tracking_uri(TRACKING_URI)\n",
    "mlflow.set_experiment(\"lgbm_6h\")\n",
    "\n",
    "# ========== 1) 資料 ==========\n",
    "feat = pd.read_parquet(FEAT_PATH)\n",
    "label = pd.read_parquet(LABEL_PATH)\n",
    "df = feat.merge(label, on=\"time\", how=\"inner\").sort_values(\"time\").reset_index(drop=True)\n",
    "times = pd.to_datetime(df[\"time\"], utc=True)\n",
    "\n",
    "y = df[\"y_dir_6h\"].astype(int).values\n",
    "X = df.drop(columns=[\"time\", \"y_dir_6h\", \"y_tail_6h\"]).values\n",
    "\n",
    "# 切分\n",
    "test_start_ts = times.max() - pd.Timedelta(days=TEST_DAYS)\n",
    "train_mask = times < test_start_ts\n",
    "test_mask = times >= test_start_ts\n",
    "\n",
    "X_train_raw, y_train_raw, t_train = X[train_mask], y[train_mask], times[train_mask]\n",
    "X_test_raw, y_test_raw, t_test = X[test_mask], y[test_mask], times[test_mask]\n",
    "\n",
    "# 縮放（沿用 TCN 的 scaler，如不存在則新 fit 一個）\n",
    "scaler_path = Path(\"./artifacts_tcn/scaler.pkl\")\n",
    "if scaler_path.exists():\n",
    "    scaler = joblib.load(scaler_path)\n",
    "else:\n",
    "    scaler = StandardScaler().fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n",
    "\n",
    "# ========== 2) Walk-Forward 切分 ==========\n",
    "def gen_walk_forward_splits(times_arr: pd.Series, train_days=270, val_days=90):\n",
    "    splits = []\n",
    "    start_date = times_arr.min()\n",
    "    end_date = times_arr.max()\n",
    "    cursor = start_date\n",
    "    while True:\n",
    "        train_end = cursor + pd.Timedelta(days=train_days)\n",
    "        val_end = train_end + pd.Timedelta(days=val_days)\n",
    "        if val_end > end_date:\n",
    "            break\n",
    "        tr_idx = (times_arr >= cursor) & (times_arr < train_end)\n",
    "        va_idx = (times_arr >= train_end) & (times_arr < val_end)\n",
    "        if tr_idx.sum() > 200 and va_idx.sum() > 50:\n",
    "            splits.append((np.where(tr_idx)[0], np.where(va_idx)[0]))\n",
    "        cursor = cursor + pd.Timedelta(days=val_days)\n",
    "    if not splits:\n",
    "        n = len(times_arr)\n",
    "        cut = int(n * 0.7)\n",
    "        splits = [(np.arange(0, cut), np.arange(cut, n))]\n",
    "    return splits\n",
    "\n",
    "cv_splits = gen_walk_forward_splits(pd.Series(t_train))\n",
    "\n",
    "# ========== 3) 調參 ==========\n",
    "param_grid = {\n",
    "    \"num_leaves\": [31, 63],\n",
    "    \"max_depth\": [-1, 7],\n",
    "    \"learning_rate\": [0.1, 0.01],\n",
    "    \"colsample_bytree\": [0.7, 1.0],\n",
    "}\n",
    "grid = list(ParameterGrid(param_grid))\n",
    "\n",
    "best_params = None\n",
    "best_cv_auc = -np.inf\n",
    "oof_preds = []\n",
    "oof_labels = []\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_cv\"):\n",
    "    for params in grid:\n",
    "        fold_aucs = []\n",
    "        for tr_idx, va_idx in cv_splits:\n",
    "            clf = lgb.LGBMClassifier(\n",
    "                objective=\"binary\",\n",
    "                metric=\"auc\",\n",
    "                n_estimators=2000,\n",
    "                reg_lambda=5.0,\n",
    "                min_child_samples=80,\n",
    "                **params\n",
    "            )\n",
    "            clf.fit(\n",
    "                X_train[tr_idx], y_train_raw[tr_idx],\n",
    "                eval_set=[(X_train[va_idx], y_train_raw[va_idx])],\n",
    "                eval_metric=\"auc\",\n",
    "                callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "            )\n",
    "            va_pred = clf.predict_proba(X_train[va_idx])[:, 1]\n",
    "            fold_aucs.append(roc_auc_score(y_train_raw[va_idx], va_pred))\n",
    "        mean_auc = float(np.mean(fold_aucs))\n",
    "        mlflow.log_param(f\"params_{params}\", str(params))\n",
    "        mlflow.log_metric(f\"cv_auc_{params}\", mean_auc)\n",
    "        if mean_auc > best_cv_auc:\n",
    "            best_cv_auc = mean_auc\n",
    "            best_params = params\n",
    "\n",
    "    # 以最佳參數重訓並收集 OOF 作校準\n",
    "    for tr_idx, va_idx in cv_splits:\n",
    "        clf = lgb.LGBMClassifier(\n",
    "            objective=\"binary\",\n",
    "            metric=\"auc\",\n",
    "            n_estimators=2000,\n",
    "            reg_lambda=5.0,\n",
    "            min_child_samples=80,\n",
    "            **best_params\n",
    "        )\n",
    "        clf.fit(\n",
    "            X_train[tr_idx], y_train_raw[tr_idx],\n",
    "            eval_set=[(X_train[va_idx], y_train_raw[va_idx])],\n",
    "            eval_metric=\"auc\",\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50, verbose=False)]\n",
    "        )\n",
    "        va_pred = clf.predict_proba(X_train[va_idx])[:, 1]\n",
    "        oof_preds.append(va_pred)\n",
    "        oof_labels.append(y_train_raw[va_idx])\n",
    "\n",
    "    oof_preds = np.concatenate(oof_preds)\n",
    "    oof_labels = np.concatenate(oof_labels)\n",
    "    mlflow.log_metric(\"best_cv_auc\", float(best_cv_auc))\n",
    "\n",
    "# ========== 4) 最終模型 ==========\n",
    "final_clf = lgb.LGBMClassifier(\n",
    "    objective=\"binary\",\n",
    "    metric=\"auc\",\n",
    "    n_estimators=3000,\n",
    "    reg_lambda=5.0,\n",
    "    min_child_samples=80,\n",
    "    **best_params\n",
    ")\n",
    "# 內部早停\n",
    "cut = int(len(X_train) * 0.9)\n",
    "final_clf.fit(\n",
    "    X_train[:cut], y_train_raw[:cut],\n",
    "    eval_set=[(X_train[cut:], y_train_raw[cut:])],\n",
    "    eval_metric=\"auc\",\n",
    "    callbacks=[lgb.early_stopping(stopping_rounds=100, verbose=False)]\n",
    ")\n",
    "\n",
    "proba_test = final_clf.predict_proba(X_test)[:, 1]\n",
    "auc_test = roc_auc_score(y_test_raw, proba_test)\n",
    "brier_test = brier_score_loss(y_test_raw, proba_test)\n",
    "\n",
    "# 校準\n",
    "calibrator = IsotonicRegression(out_of_bounds=\"clip\").fit(oof_preds, oof_labels)\n",
    "proba_test_cal = calibrator.transform(proba_test)\n",
    "brier_test_cal = brier_score_loss(y_test_raw, proba_test_cal)\n",
    "\n",
    "# 保存\n",
    "joblib.dump(final_clf, ART_DIR / \"lgbm_model.pkl\")\n",
    "final_clf.booster_.save_model(str(ART_DIR / \"lgbm_model.txt\"))\n",
    "joblib.dump(calibrator, ART_DIR / \"lgbm_calibrator.pkl\")\n",
    "joblib.dump(scaler, ART_DIR / \"scaler.pkl\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"lgbm_final\"):\n",
    "    mlflow.log_param(\"best_params\", str(best_params))\n",
    "    mlflow.log_metric(\"test_auc_raw\", float(auc_test))\n",
    "    mlflow.log_metric(\"test_brier_raw\", float(brier_test))\n",
    "    mlflow.log_metric(\"test_brier_cal\", float(brier_test_cal))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_model.pkl\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_model.txt\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"lgbm_calibrator.pkl\"))\n",
    "    mlflow.log_artifact(str(ART_DIR / \"scaler.pkl\"))\n",
    "\n",
    "print({\n",
    "    \"best_cv_auc\": float(best_cv_auc),\n",
    "    \"test_auc_raw\": float(auc_test),\n",
    "    \"test_brier_raw\": float(brier_test),\n",
    "    \"test_brier_cal\": float(brier_test_cal),\n",
    "})\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
