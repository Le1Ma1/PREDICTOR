{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da17d8d3",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 目的：從 Supabase 抓取 6h 原始表，時間排序、補齊 6h 間隔，存為 Parquet\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# ========== 0) 參數 ==========\n",
    "TABLES = [\n",
    "    \"clean_price_ohlcv_6h\",\n",
    "    \"clean_agg_oi_6h\",\n",
    "    \"clean_funding_6h\",\n",
    "    \"clean_liq_agg_6h\",\n",
    "    \"clean_lsr_6h\",\n",
    "    \"clean_taker_flow_6h\",\n",
    "]\n",
    "OUTPUT_DIR = Path(\"./data/parquet_raw_6h\")\n",
    "PAGE_SIZE = 1000  # Supabase REST 單次返回上限；用 range 迭代抓全量\n",
    "TIME_COL = \"ts_utc\"     # 對齊時間戳\n",
    "TS_UTC_COL = \"ts_utc\" # 上載時間戳（若無則略過）\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== 1) 連線 ==========\n",
    "load_dotenv()\n",
    "SUPABASE_URL = os.environ[\"SUPABASE_URL\"]\n",
    "SUPABASE_KEY = os.environ[\"SUPABASE_KEY\"]\n",
    "supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)\n",
    "\n",
    "# ========== 2) 通用抓取（含分頁） ==========\n",
    "def fetch_all_rows(table: str, order_by: str = TIME_COL, page_size: int = PAGE_SIZE) -> List[Dict[str, Any]]:\n",
    "    out: List[Dict[str, Any]] = []\n",
    "    start = 0\n",
    "    while True:\n",
    "        resp = (\n",
    "            supabase.table(table)\n",
    "            .select(\"*\")\n",
    "            .order(order_by, desc=False)\n",
    "            .range(start, start + page_size - 1)\n",
    "            .execute()\n",
    "        )\n",
    "        rows = resp.data or []\n",
    "        out.extend(rows)\n",
    "        if len(rows) < page_size:\n",
    "            break\n",
    "        start += page_size\n",
    "    return out\n",
    "\n",
    "# ========== 3) 整理時間序並補齊 6H ==========\n",
    "def normalize_df(df: pd.DataFrame, time_col: str = TIME_COL) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    # 時間戳轉為 UTC DateTime\n",
    "    # 支援秒或毫秒級 Unix（自動判斷）\n",
    "    ts = pd.to_datetime(df[time_col], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "    if ts.isna().all():  # 嘗試秒級\n",
    "        ts = pd.to_datetime(df[time_col], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "    df = df.copy()\n",
    "    df[time_col] = ts\n",
    "    if TS_UTC_COL in df.columns:\n",
    "        tsu = pd.to_datetime(df[TS_UTC_COL], unit=\"ms\", utc=True, errors=\"coerce\")\n",
    "        if tsu.isna().all():\n",
    "            tsu = pd.to_datetime(df[TS_UTC_COL], unit=\"s\", utc=True, errors=\"coerce\")\n",
    "        df[TS_UTC_COL] = tsu\n",
    "    # 設 index 與排序\n",
    "    df = df.set_index(time_col).sort_index()\n",
    "    # 以現有範圍補齊 6H 間隔\n",
    "    full_idx = pd.date_range(start=df.index.min(), end=df.index.max(), freq=\"6H\", tz=\"UTC\")\n",
    "    df = df.reindex(full_idx)\n",
    "    # 不做值填補，保留 NaN 以供後續對齊（或可使用 ffill 視需求）\n",
    "    df.index.name = time_col\n",
    "    return df\n",
    "\n",
    "# ========== 4) 主程式 ==========\n",
    "for tbl in TABLES:\n",
    "    rows = fetch_all_rows(tbl)\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        print(f\"[WARN] {tbl} 無資料，略過\")\n",
    "        continue\n",
    "    df = normalize_df(df, TIME_COL)\n",
    "    out_path = OUTPUT_DIR / f\"{tbl}.parquet\"\n",
    "    df.to_parquet(out_path, index=True)\n",
    "    print(f\"[OK] {tbl} -> {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
