{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd412d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# 匯出 Champion 模型 (LGBM, 用 onnxmltools) 與 Baseline (LogReg, 用 skl2onnx) 為 ONNX\n",
    "\n",
    "# 安裝必要套件\n",
    "!pip install -q onnxmltools skl2onnx onnxruntime lightgbm\n",
    "\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import numpy as np\n",
    "import onnxruntime as ort\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 匯出工具\n",
    "from onnxmltools.convert import convert_lightgbm\n",
    "from onnxmltools.convert.common.data_types import FloatTensorType as FloatTensorType_onnx\n",
    "from skl2onnx import convert_sklearn\n",
    "from skl2onnx.common.data_types import FloatTensorType as FloatTensorType_skl\n",
    "\n",
    "# ========== 0) 路徑 ==========\n",
    "ART_LGBM = Path(\"./artifacts_lgbm\")\n",
    "ART_ONNX = Path(\"./onnx_models\")\n",
    "ART_ONNX.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ========== 1) 載入模型 ==========\n",
    "# LGBM Champion\n",
    "lgbm_model = joblib.load(ART_LGBM / \"lgbm_model.pkl\")\n",
    "scaler = joblib.load(ART_LGBM / \"scaler.pkl\")\n",
    "\n",
    "# Logistic Regression Baseline (重新訓練)\n",
    "feat = pd.read_parquet(\"./data/feat_6h.parquet\")\n",
    "label = pd.read_parquet(\"./data/label_6h.parquet\")\n",
    "df = feat.merge(label, on=\"ts_utc\", how=\"inner\").sort_values(\"ts_utc\")\n",
    "\n",
    "X = df.drop(columns=[\"ts_utc\",\"y_dir_6h\",\"y_tail_6h\"]).select_dtypes(include=[np.number]).values\n",
    "y = df[\"y_dir_6h\"].astype(int).values\n",
    "X_scaled = scaler.transform(X)\n",
    "\n",
    "logreg_model = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "logreg_model.fit(X_scaled, y)\n",
    "\n",
    "# ========== 2) 匯出 LGBM ==========\n",
    "feature_dim = scaler.mean_.shape[0]\n",
    "onnx_lgbm = convert_lightgbm(\n",
    "    lgbm_model.booster_,\n",
    "    initial_types=[('input', FloatTensorType_onnx([None, feature_dim]))],\n",
    "    target_opset=15\n",
    ")\n",
    "with open(ART_ONNX / \"lgbm_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_lgbm.SerializeToString())\n",
    "print(\"[OK] LGBM 匯出完成 -> lgbm_model.onnx\")\n",
    "\n",
    "# ========== 3) 匯出 Logistic Regression ==========\n",
    "onnx_logreg = convert_sklearn(\n",
    "    logreg_model,\n",
    "    initial_types=[('input', FloatTensorType_skl([None, feature_dim]))]\n",
    ")\n",
    "with open(ART_ONNX / \"logreg_model.onnx\", \"wb\") as f:\n",
    "    f.write(onnx_logreg.SerializeToString())\n",
    "print(\"[OK] Logistic Regression 匯出完成 -> logreg_model.onnx\")\n",
    "\n",
    "# ========== 4) 驗證 ONNX 模型 ==========\n",
    "X_dummy = scaler.transform(np.random.rand(1, feature_dim))\n",
    "\n",
    "for name, model_path in [(\"LGBM\", \"lgbm_model.onnx\"), (\"LogReg\", \"logreg_model.onnx\")]:\n",
    "    sess = ort.InferenceSession(str(ART_ONNX / model_path))\n",
    "    input_name = sess.get_inputs()[0].name\n",
    "    pred = sess.run(None, {input_name: X_dummy.astype(np.float32)})[0]\n",
    "    print(f\"[Check] {name} 輸出機率: {pred}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
